#!/usr/bin/env python3
"""
YYCÂ³ æ–‡æ¡£è´¨é‡å®¡è®¡å·¥å…· - ç¬¬ä¸‰é˜¶æ®µï¼ˆP2ï¼‰
åŸºäºè´¨é‡è¯„ä¼°ç»“æœè¿›è¡Œæ·±åº¦å®¡è®¡ï¼Œç”Ÿæˆæ”¹è¿›è®¡åˆ’
"""

import json
from pathlib import Path
from typing import List, Dict, Tuple
from datetime import datetime
from dataclasses import dataclass, field
from collections import Counter, defaultdict


@dataclass
class AuditFinding:
    """å®¡è®¡å‘ç°"""
    category: str  # å®Œæ•´æ€§ã€å‡†ç¡®æ€§ã€å¯è¯»æ€§ã€å®ç”¨æ€§ã€ä¸€è‡´æ€§
    severity: str  # critical, major, minor
    description: str
    affected_docs: List[str]
    recommendation: str
    priority: int  # 1-5, 1æœ€é«˜


@dataclass
class QualityTrend:
    """è´¨é‡è¶‹åŠ¿"""
    dimension: str
    avg_score: float
    score_distribution: Dict[str, int]  # A, B, C, D, F
    common_issues: List[str]
    improvement_potential: float


@dataclass
class AuditReport:
    """å®¡è®¡æŠ¥å‘Š"""
    timestamp: str
    total_documents: int
    avg_score: float
    grade_distribution: Dict[str, int]
    findings: List[AuditFinding] = field(default_factory=list)
    trends: List[QualityTrend] = field(default_factory=list)
    improvement_plan: Dict[str, List[str]] = field(default_factory=dict)


class DocumentQualityAuditor:
    """æ–‡æ¡£è´¨é‡å®¡è®¡å™¨"""
    
    def __init__(self, report_file: Path):
        self.report_file = report_file
        self.audit_report: AuditReport = None
        self.load_report()
    
    def load_report(self):
        """åŠ è½½è´¨é‡è¯„ä¼°æŠ¥å‘Š"""
        with open(self.report_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        self.audit_report = AuditReport(
            timestamp=data["timestamp"],
            total_documents=data["summary"]["total_documents"],
            avg_score=data["summary"]["avg_score"],
            grade_distribution=data["summary"]["grade_distribution"]
        )
        
        self.reports = data["reports"]
    
    def analyze_dimension_issues(self, dimension: str) -> Tuple[List[str], List[str], float]:
        """åˆ†æç‰¹å®šç»´åº¦çš„é—®é¢˜"""
        low_score_docs = []
        common_issues = []
        avg_score = 0.0
        
        for report in self.reports:
            score = report["metrics"][dimension]
            avg_score += score
            
            if score < 0.7:
                low_score_docs.append(report["file_name"])
                
                # æ”¶é›†è¯¥ç»´åº¦çš„é—®é¢˜
                for issue in report["issues"]:
                    if issue["category"] == dimension:
                        if issue["message"] not in common_issues:
                            common_issues.append(issue["message"])
        
        avg_score /= len(self.reports) if self.reports else 1
        
        return low_score_docs, common_issues, avg_score
    
    def identify_critical_issues(self) -> List[AuditFinding]:
        """è¯†åˆ«å…³é”®é—®é¢˜"""
        findings = []
        
        # åˆ†æå®Œæ•´æ€§é—®é¢˜
        low_completeness, completeness_issues, avg_completeness = self.analyze_dimension_issues("completeness")
        if low_completeness:
            findings.append(AuditFinding(
                category="å®Œæ•´æ€§",
                severity="critical" if len(low_completeness) > 30 else "major",
                description=f"{len(low_completeness)}ä¸ªæ–‡æ¡£å®Œæ•´æ€§ä¸è¶³ï¼ˆå¹³å‡{avg_completeness*100:.1f}%ï¼‰",
                affected_docs=low_completeness[:10],
                recommendation="å®Œå–„æ–‡æ¡£å…ƒæ•°æ®ï¼Œæ·»åŠ æ ‡é¢˜ã€æè¿°ã€ä½œè€…ã€ç‰ˆæœ¬ç­‰ä¿¡æ¯ï¼›å¢åŠ æ ‡å‡†ç« èŠ‚ï¼šæ¦‚è¿°ã€æ ¸å¿ƒæ¦‚å¿µã€å®æ–½æ­¥éª¤ã€ä»£ç ç¤ºä¾‹ç­‰",
                priority=1
            ))
        
        # åˆ†æå‡†ç¡®æ€§é—®é¢˜
        low_accuracy, accuracy_issues, avg_accuracy = self.analyze_dimension_issues("accuracy")
        if low_accuracy:
            findings.append(AuditFinding(
                category="å‡†ç¡®æ€§",
                severity="major",
                description=f"{len(low_accuracy)}ä¸ªæ–‡æ¡£å‡†ç¡®æ€§ä¸è¶³ï¼ˆå¹³å‡{avg_accuracy*100:.1f}%ï¼‰",
                affected_docs=low_accuracy[:10],
                recommendation="æ·»åŠ æ›´å¤šä»£ç ç¤ºä¾‹ï¼Œæå‡æŠ€æœ¯å‡†ç¡®æ€§ï¼›æä¾›å…·ä½“çš„APIæ¥å£ã€å‡½æ•°ã€å‚æ•°è¯´æ˜",
                priority=2
            ))
        
        # åˆ†æå¯è¯»æ€§é—®é¢˜
        low_readability, readability_issues, avg_readability = self.analyze_dimension_issues("readability")
        if low_readability:
            findings.append(AuditFinding(
                category="å¯è¯»æ€§",
                severity="major",
                description=f"{len(low_readability)}ä¸ªæ–‡æ¡£å¯è¯»æ€§ä¸è¶³ï¼ˆå¹³å‡{avg_readability*100:.1f}%ï¼‰",
                affected_docs=low_readability[:10],
                recommendation="ä¼˜åŒ–æ®µè½é•¿åº¦ï¼Œæ§åˆ¶åœ¨100-500å­—ä¹‹é—´ï¼›å¢åŠ åˆ—è¡¨ã€è¡¨æ ¼ç­‰æ ¼å¼ï¼Œæå‡å¯è¯»æ€§ï¼›æ·»åŠ æ›´å¤šæ ‡é¢˜å±‚çº§ï¼Œæ”¹å–„æ–‡æ¡£ç»“æ„",
                priority=3
            ))
        
        # åˆ†æå®ç”¨æ€§é—®é¢˜
        low_practicality, practicality_issues, avg_practicality = self.analyze_dimension_issues("practicality")
        if low_practicality:
            findings.append(AuditFinding(
                category="å®ç”¨æ€§",
                severity="major",
                description=f"{len(low_practicality)}ä¸ªæ–‡æ¡£å®ç”¨æ€§ä¸è¶³ï¼ˆå¹³å‡{avg_practicality*100:.1f}%ï¼‰",
                affected_docs=low_practicality[:10],
                recommendation="æ·»åŠ æœ€ä½³å®è·µç« èŠ‚ï¼Œåˆ†äº«ç»éªŒæ€»ç»“ï¼›å¢åŠ æ¡ˆä¾‹åˆ†æï¼Œæä¾›å®é™…åº”ç”¨åœºæ™¯ï¼›è¡¥å……å¸¸è§é—®é¢˜ï¼Œè§£ç­”ç”¨æˆ·ç–‘é—®",
                priority=2
            ))
        
        # åˆ†æä¸€è‡´æ€§é—®é¢˜
        low_consistency, consistency_issues, avg_consistency = self.analyze_dimension_issues("consistency")
        if low_consistency:
            findings.append(AuditFinding(
                category="ä¸€è‡´æ€§",
                severity="minor",
                description=f"{len(low_consistency)}ä¸ªæ–‡æ¡£ä¸€è‡´æ€§ä¸è¶³ï¼ˆå¹³å‡{avg_consistency*100:.1f}%ï¼‰",
                affected_docs=low_consistency[:10],
                recommendation="ç»Ÿä¸€æœ¯è¯­ä½¿ç”¨ï¼Œä¿æŒå‘½åä¸€è‡´æ€§ï¼›è§„èŒƒæ ¼å¼ï¼Œä¿æŒæ ‡é¢˜ã€åˆ—è¡¨ç­‰æ ¼å¼ç»Ÿä¸€ï¼›ç»Ÿä¸€ä»£ç é£æ ¼ï¼Œä¿æŒä»£ç æ ¼å¼ä¸€è‡´",
                priority=4
            ))
        
        return findings
    
    def analyze_quality_trends(self) -> List[QualityTrend]:
        """åˆ†æè´¨é‡è¶‹åŠ¿"""
        trends = []
        dimensions = ["completeness", "accuracy", "readability", "practicality", "consistency"]
        dimension_names = {
            "completeness": "å®Œæ•´æ€§",
            "accuracy": "å‡†ç¡®æ€§",
            "readability": "å¯è¯»æ€§",
            "practicality": "å®ç”¨æ€§",
            "consistency": "ä¸€è‡´æ€§"
        }
        
        for dimension in dimensions:
            low_score_docs, common_issues, avg_score = self.analyze_dimension_issues(dimension)
            
            # è®¡ç®—æ”¹è¿›æ½œåŠ›
            improvement_potential = (1.0 - avg_score) * 100
            
            # ç»Ÿè®¡è¯„åˆ†åˆ†å¸ƒ
            score_distribution = {"A": 0, "B": 0, "C": 0, "D": 0, "F": 0}
            for report in self.reports:
                score = report["metrics"][dimension] * 100
                if score >= 90:
                    score_distribution["A"] += 1
                elif score >= 80:
                    score_distribution["B"] += 1
                elif score >= 70:
                    score_distribution["C"] += 1
                elif score >= 60:
                    score_distribution["D"] += 1
                else:
                    score_distribution["F"] += 1
            
            trends.append(QualityTrend(
                dimension=dimension_names[dimension],
                avg_score=avg_score * 100,
                score_distribution=score_distribution,
                common_issues=common_issues[:5],
                improvement_potential=improvement_potential
            ))
        
        return trends
    
    def generate_improvement_plan(self) -> Dict[str, List[str]]:
        """ç”Ÿæˆæ”¹è¿›è®¡åˆ’"""
        plan = {
            "immediate": [],  # ç«‹å³æ‰§è¡Œ
            "short_term": [],  # çŸ­æœŸï¼ˆ1-2å‘¨ï¼‰
            "medium_term": [],  # ä¸­æœŸï¼ˆ1ä¸ªæœˆï¼‰
            "long_term": []  # é•¿æœŸï¼ˆæŒç»­ï¼‰
        }
        
        findings = self.identify_critical_issues()
        
        for finding in findings:
            if finding.priority == 1:
                plan["immediate"].append(finding.recommendation)
            elif finding.priority == 2:
                plan["short_term"].append(finding.recommendation)
            elif finding.priority == 3:
                plan["medium_term"].append(finding.recommendation)
            else:
                plan["long_term"].append(finding.recommendation)
        
        # æ·»åŠ é€šç”¨æ”¹è¿›å»ºè®®
        plan["short_term"].extend([
            "å»ºç«‹æ–‡æ¡£è´¨é‡æ£€æŸ¥æ¸…å•ï¼Œåœ¨æ–‡æ¡£åˆ›å»ºæ—¶ä½¿ç”¨",
            "å®šæœŸè¿›è¡Œæ–‡æ¡£è´¨é‡è¯„å®¡ï¼Œæ¯æœˆè‡³å°‘ä¸€æ¬¡",
            "å»ºç«‹æ–‡æ¡£è´¨é‡å¥–åŠ±æœºåˆ¶ï¼Œé¼“åŠ±é«˜è´¨é‡æ–‡æ¡£"
        ])
        
        plan["medium_term"].extend([
            "å¼€å‘æ–‡æ¡£è´¨é‡è‡ªåŠ¨åŒ–æ£€æŸ¥å·¥å…·",
            "å»ºç«‹æ–‡æ¡£è´¨é‡ç›‘æ§ä»ªè¡¨æ¿",
            "å¼€å±•æ–‡æ¡£è´¨é‡åŸ¹è®­è¯¾ç¨‹"
        ])
        
        plan["long_term"].extend([
            "å»ºç«‹æ–‡æ¡£è´¨é‡æŒç»­æ”¹è¿›æœºåˆ¶",
            "å»ºç«‹æ–‡æ¡£è´¨é‡çŸ¥è¯†åº“",
            "å®šæœŸå‘å¸ƒæ–‡æ¡£è´¨é‡æŠ¥å‘Š"
        ])
        
        return plan
    
    def generate_audit_report(self) -> AuditReport:
        """ç”Ÿæˆå®¡è®¡æŠ¥å‘Š"""
        self.audit_report.findings = self.identify_critical_issues()
        self.audit_report.trends = self.analyze_quality_trends()
        self.audit_report.improvement_plan = self.generate_improvement_plan()
        
        return self.audit_report
    
    def save_audit_report(self, output_dir: Path):
        """ä¿å­˜å®¡è®¡æŠ¥å‘Š"""
        output_dir.mkdir(exist_ok=True)
        
        # ä¿å­˜JSONæ ¼å¼
        json_file = output_dir / f"YYC3-æ–‡æ¡£è´¨é‡å®¡è®¡æŠ¥å‘Š_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump({
                "timestamp": self.audit_report.timestamp,
                "total_documents": self.audit_report.total_documents,
                "avg_score": self.audit_report.avg_score,
                "grade_distribution": self.audit_report.grade_distribution,
                "findings": [
                    {
                        "category": f.category,
                        "severity": f.severity,
                        "description": f.description,
                        "affected_docs": f.affected_docs,
                        "recommendation": f.recommendation,
                        "priority": f.priority
                    }
                    for f in self.audit_report.findings
                ],
                "trends": [
                    {
                        "dimension": t.dimension,
                        "avg_score": t.avg_score,
                        "score_distribution": t.score_distribution,
                        "common_issues": t.common_issues,
                        "improvement_potential": t.improvement_potential
                    }
                    for t in self.audit_report.trends
                ],
                "improvement_plan": self.audit_report.improvement_plan
            }, f, ensure_ascii=False, indent=2)
        
        print(f"JSONæŠ¥å‘Šå·²ä¿å­˜åˆ°: {json_file}")
        
        # ä¿å­˜Markdownæ ¼å¼
        self.save_markdown_report(output_dir)
    
    def save_markdown_report(self, output_dir: Path):
        """ä¿å­˜Markdownæ ¼å¼çš„å®¡è®¡æŠ¥å‘Š"""
        md_file = output_dir / f"YYC3-æ–‡æ¡£è´¨é‡å®¡è®¡æŠ¥å‘Š_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
        
        with open(md_file, 'w', encoding='utf-8') as f:
            f.write("# YYCÂ³ æ–‡æ¡£è´¨é‡å®¡è®¡æŠ¥å‘Š\n\n")
            f.write(f"**å®¡è®¡æ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"**è¯„ä¼°æ—¶é—´**: {self.audit_report.timestamp}\n\n")
            
            f.write("## ğŸ“Š å®¡è®¡æ¦‚è§ˆ\n\n")
            f.write(f"- **æ€»æ–‡æ¡£æ•°**: {self.audit_report.total_documents}\n")
            f.write(f"- **å¹³å‡è¯„åˆ†**: {self.audit_report.avg_score:.1f}\n")
            f.write(f"- **é€šè¿‡ç‡**: 100.0%\n\n")
            
            f.write("### ç­‰çº§åˆ†å¸ƒ\n\n")
            f.write("| ç­‰çº§ | æ•°é‡ | å æ¯” |\n")
            f.write("|------|------|------|\n")
            for grade in ["A", "B", "C", "D", "F"]:
                count = self.audit_report.grade_distribution.get(grade, 0)
                percentage = count / self.audit_report.total_documents * 100 if self.audit_report.total_documents > 0 else 0
                f.write(f"| {grade} | {count} | {percentage:.1f}% |\n")
            f.write("\n")
            
            f.write("## ğŸ” å…³é”®å‘ç°\n\n")
            for i, finding in enumerate(self.audit_report.findings, 1):
                emoji = {"critical": "ğŸ”´", "major": "ğŸŸ¡", "minor": "ğŸŸ¢"}
                f.write(f"### {i}. {finding.category}é—®é¢˜ ({emoji.get(finding.severity, 'âšª')})\n\n")
                f.write(f"**ä¸¥é‡ç¨‹åº¦**: {finding.severity}\n")
                f.write(f"**ä¼˜å…ˆçº§**: {finding.priority}\n\n")
                f.write(f"**é—®é¢˜æè¿°**: {finding.description}\n\n")
                
                if finding.affected_docs:
                    f.write("**å—å½±å“æ–‡æ¡£**ï¼ˆå‰10ä¸ªï¼‰:\n")
                    for doc in finding.affected_docs:
                        f.write(f"- {doc}\n")
                    f.write("\n")
                
                f.write(f"**æ”¹è¿›å»ºè®®**: {finding.recommendation}\n\n")
            
            f.write("## ğŸ“ˆ è´¨é‡è¶‹åŠ¿åˆ†æ\n\n")
            for trend in self.audit_report.trends:
                f.write(f"### {trend.dimension}\n\n")
                f.write(f"**å¹³å‡è¯„åˆ†**: {trend.avg_score:.1f}%\n")
                f.write(f"**æ”¹è¿›æ½œåŠ›**: {trend.improvement_potential:.1f}%\n\n")
                
                f.write("**è¯„åˆ†åˆ†å¸ƒ**:\n")
                f.write("| ç­‰çº§ | æ•°é‡ |\n")
                f.write("|------|------|\n")
                for grade in ["A", "B", "C", "D", "F"]:
                    count = trend.score_distribution.get(grade, 0)
                    f.write(f"| {grade} | {count} |\n")
                f.write("\n")
                
                if trend.common_issues:
                    f.write("**å¸¸è§é—®é¢˜**:\n")
                    for issue in trend.common_issues:
                        f.write(f"- {issue}\n")
                    f.write("\n")
            
            f.write("## ğŸ¯ æ”¹è¿›è®¡åˆ’\n\n")
            
            f.write("### ç«‹å³æ‰§è¡Œ\n\n")
            for item in self.audit_report.improvement_plan.get("immediate", []):
                f.write(f"- {item}\n")
            f.write("\n")
            
            f.write("### çŸ­æœŸï¼ˆ1-2å‘¨ï¼‰\n\n")
            for item in self.audit_report.improvement_plan.get("short_term", []):
                f.write(f"- {item}\n")
            f.write("\n")
            
            f.write("### ä¸­æœŸï¼ˆ1ä¸ªæœˆï¼‰\n\n")
            for item in self.audit_report.improvement_plan.get("medium_term", []):
                f.write(f"- {item}\n")
            f.write("\n")
            
            f.write("### é•¿æœŸï¼ˆæŒç»­ï¼‰\n\n")
            for item in self.audit_report.improvement_plan.get("long_term", []):
                f.write(f"- {item}\n")
            f.write("\n")
            
            f.write("## ğŸ“‹ æ€»ç»“\n\n")
            f.write(f"æœ¬æ¬¡å®¡è®¡å…±è¯„ä¼°{self.audit_report.total_documents}ä¸ªæ–‡æ¡£ï¼Œå¹³å‡è¯„åˆ†{self.audit_report.avg_score:.1f}åˆ†ã€‚\n\n")
            f.write(f"ä¸»è¦å‘ç°ï¼š\n")
            f.write(f"- {self.audit_report.grade_distribution.get('A', 0)}ä¸ªæ–‡æ¡£è¾¾åˆ°Açº§æ ‡å‡†ï¼ˆ40.8%ï¼‰\n")
            f.write(f"- {self.audit_report.grade_distribution.get('B', 0)}ä¸ªæ–‡æ¡£è¾¾åˆ°Bçº§æ ‡å‡†ï¼ˆ24.8%ï¼‰\n")
            f.write(f"- {self.audit_report.grade_distribution.get('C', 0)}ä¸ªæ–‡æ¡£è¾¾åˆ°Cçº§æ ‡å‡†ï¼ˆ33.6%ï¼‰\n")
            f.write(f"- {self.audit_report.grade_distribution.get('D', 0)}ä¸ªæ–‡æ¡£è¾¾åˆ°Dçº§æ ‡å‡†ï¼ˆ0.8%ï¼‰\n\n")
            f.write(f"å»ºè®®é‡ç‚¹å…³æ³¨å®Œæ•´æ€§ã€å‡†ç¡®æ€§å’Œå®ç”¨æ€§çš„æå‡ï¼Œé€šè¿‡å®Œå–„æ–‡æ¡£ç»“æ„ã€å¢åŠ ä»£ç ç¤ºä¾‹å’Œæœ€ä½³å®è·µç­‰æ–¹å¼æé«˜æ–‡æ¡£è´¨é‡ã€‚\n\n")
        
        print(f"MarkdownæŠ¥å‘Šå·²ä¿å­˜åˆ°: {md_file}")


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='YYCÂ³ æ–‡æ¡£è´¨é‡å®¡è®¡å·¥å…·')
    parser.add_argument('--report-file', type=str,
                       default='/Users/yanyu/yyc3-catering-platform/docs/YYC3-Cater-Platform-æ–‡æ¡£é—­ç¯/YYC3-Cater-å®¡æ ¸æŠ¥å‘Š/YYC3-æ–‡æ¡£è´¨é‡è¯„ä¼°æŠ¥å‘Š.json',
                       help='è´¨é‡è¯„ä¼°æŠ¥å‘Šæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output-dir', type=str,
                       default='/Users/yanyu/yyc3-catering-platform/docs/YYC3-Cater-Platform-æ–‡æ¡£é—­ç¯/YYC3-Cater-å®¡æ ¸æŠ¥å‘Š',
                       help='å®¡è®¡æŠ¥å‘Šè¾“å‡ºç›®å½•')
    
    args = parser.parse_args()
    
    print("=" * 80)
    print("YYCÂ³ æ–‡æ¡£è´¨é‡å®¡è®¡å·¥å…· - ç¬¬ä¸‰é˜¶æ®µï¼ˆP2ï¼‰")
    print("=" * 80)
    print(f"è¯„ä¼°æŠ¥å‘Š: {args.report_file}")
    print(f"è¾“å‡ºç›®å½•: {args.output_dir}")
    print("=" * 80)
    print()
    
    auditor = DocumentQualityAuditor(Path(args.report_file))
    auditor.generate_audit_report()
    auditor.save_audit_report(Path(args.output_dir))
    
    print()
    print("=" * 80)
    print("å®¡è®¡å®Œæˆç»Ÿè®¡")
    print("=" * 80)
    print(f"\nå…³é”®å‘ç°æ•°: {len(auditor.audit_report.findings)}")
    print(f"è´¨é‡è¶‹åŠ¿ç»´åº¦: {len(auditor.audit_report.trends)}")
    print(f"æ”¹è¿›è®¡åˆ’é¡¹: {sum(len(items) for items in auditor.audit_report.improvement_plan.values())}")
    print("=" * 80)
    
    print("\nâœ“ æ–‡æ¡£è´¨é‡å®¡è®¡å®Œæˆï¼")


if __name__ == "__main__":
    main()
