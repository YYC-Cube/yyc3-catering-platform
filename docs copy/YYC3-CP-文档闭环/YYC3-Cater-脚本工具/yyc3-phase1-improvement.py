#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
@file: yyc3-phase1-improvement.py
@description: YYCÂ³æ–‡æ¡£é—­ç¯ç³»ç»Ÿç¬¬ä¸€é˜¶æ®µï¼ˆP0ï¼‰æ”¹è¿›è„šæœ¬
@author: YYCÂ³
@version: 1.0.0
@created: 2025-01-30
@copyright: Copyright (c) 2025 YYCÂ³
@license: MIT
"""

import os
import re
from pathlib import Path
from typing import Dict, List, Tuple
import sys

# æ–‡æ¡£æ ¹ç›®å½•
DOCS_ROOT = "/Users/yanyu/yyc3-catering-platform/docs/YYC3-Cater-Platform-æ–‡æ¡£é—­ç¯"

# æ ‡å‡†ç« èŠ‚æ¨¡æ¿
STANDARD_SECTIONS = {
    "æ¶æ„è®¾è®¡": [
        "## 1. æ¦‚è¿°",
        "### 1.1 è®¾è®¡ç›®æ ‡",
        "### 1.2 è®¾è®¡åŸåˆ™",
        "### 1.3 æŠ€æœ¯é€‰å‹",
        "## 2. æ¶æ„è®¾è®¡",
        "### 2.1 æ•´ä½“æ¶æ„",
        "### 2.2 æ¨¡å—åˆ’åˆ†",
        "### 2.3 æ•°æ®æµå‘",
        "## 3. æŠ€æœ¯å®ç°",
        "### 3.1 æ ¸å¿ƒæŠ€æœ¯",
        "### 3.2 å…³é”®ç®—æ³•",
        "### 3.3 æ€§èƒ½ä¼˜åŒ–",
        "## 4. æ¥å£è®¾è®¡",
        "### 4.1 APIæ¥å£",
        "### 4.2 æ•°æ®æ¥å£",
        "### 4.3 æ¶ˆæ¯æ¥å£",
        "## 5. éƒ¨ç½²æ–¹æ¡ˆ",
        "### 5.1 éƒ¨ç½²æ¶æ„",
        "### 5.2 é…ç½®ç®¡ç†",
        "### 5.3 ç›‘æ§å‘Šè­¦",
        "## 6. é™„å½•",
        "### 6.1 æœ¯è¯­è¡¨",
        "### 6.2 å‚è€ƒèµ„æ–™"
    ],
    "å¼€å‘å®æ–½": [
        "## 1. æ¦‚è¿°",
        "### 1.1 åŠŸèƒ½è¯´æ˜",
        "### 1.2 æŠ€æœ¯æ ˆ",
        "### 1.3 å¼€å‘ç¯å¢ƒ",
        "## 2. å®ç°æ–¹æ¡ˆ",
        "### 2.1 ä»£ç ç»“æ„",
        "### 2.2 æ ¸å¿ƒé€»è¾‘",
        "### 2.3 æ•°æ®å¤„ç†",
        "## 3. æ¥å£æ–‡æ¡£",
        "### 3.1 APIæ¥å£",
        "### 3.2 è¯·æ±‚å‚æ•°",
        "### 3.3 å“åº”æ ¼å¼",
        "## 4. æµ‹è¯•æ–¹æ¡ˆ",
        "### 4.1 å•å…ƒæµ‹è¯•",
        "### 4.2 é›†æˆæµ‹è¯•",
        "### 4.3 æµ‹è¯•ç”¨ä¾‹",
        "## 5. éƒ¨ç½²æŒ‡å—",
        "### 5.1 ç¯å¢ƒå‡†å¤‡",
        "### 5.2 éƒ¨ç½²æ­¥éª¤",
        "### 5.3 éªŒè¯æ–¹æ³•",
        "## 6. å¸¸è§é—®é¢˜",
        "### 6.1 é—®é¢˜æ’æŸ¥",
        "### 6.2 è§£å†³æ–¹æ¡ˆ"
    ],
    "æŠ€å·§ç±»": [
        "## 1. æ¦‚è¿°",
        "### 1.1 æŠ€å·§è¯´æ˜",
        "### 1.2 é€‚ç”¨åœºæ™¯",
        "### 1.3 æ³¨æ„äº‹é¡¹",
        "## 2. æŠ€å·§è¯¦è§£",
        "### 2.1 æ ¸å¿ƒæŠ€å·§",
        "### 2.2 å®è·µæ¡ˆä¾‹",
        "### 2.3 æœ€ä½³å®è·µ",
        "## 3. å®æ–½æŒ‡å—",
        "### 3.1 å®æ–½æ­¥éª¤",
        "### 3.2 å…³é”®è¦ç‚¹",
        "### 3.3 å¸¸è§é—®é¢˜",
        "## 4. å·¥å…·æ¨è",
        "### 4.1 æ¨èå·¥å…·",
        "### 4.2 ä½¿ç”¨æ–¹æ³•",
        "### 4.3 æ•ˆæœå¯¹æ¯”",
        "## 5. å‚è€ƒèµ„æº",
        "### 5.1 å®˜æ–¹æ–‡æ¡£",
        "### 5.2 ç¤¾åŒºèµ„æº",
        "### 5.3 å­¦ä¹ èµ„æ–™"
    ],
    "é»˜è®¤": [
        "## 1. æ¦‚è¿°",
        "### 1.1 è¯´æ˜",
        "### 1.2 ç›®æ ‡",
        "### 1.3 èŒƒå›´",
        "## 2. è¯¦ç»†å†…å®¹",
        "### 2.1 æ ¸å¿ƒå†…å®¹",
        "### 2.2 å®ç°ç»†èŠ‚",
        "### 2.3 æ³¨æ„äº‹é¡¹",
        "## 3. å‚è€ƒä¿¡æ¯",
        "### 3.1 ç›¸å…³æ–‡æ¡£",
        "### 3.2 å‚è€ƒèµ„æ–™",
        "### 3.3 é™„å½•"
    ]
}

# æ–‡æ¡£ä¿¡æ¯è¡¨æ ¼æ¨¡æ¿
DOC_INFO_TABLE = """## ğŸ“‹ æ–‡æ¡£ä¿¡æ¯

| å±æ€§ | å†…å®¹ |
|------|------|
| **æ–‡æ¡£æ ‡é¢˜** | {title} |
| **æ–‡æ¡£ç±»å‹** | {doc_type} |
| **æ‰€å±é˜¶æ®µ** | {phase} |
| **éµå¾ªè§„èŒƒ** | YYCÂ³ å›¢é˜Ÿæ ‡å‡†åŒ–è§„èŒƒ v1.0.0 |
| **ç‰ˆæœ¬å·** | {version} |
| **åˆ›å»ºæ—¥æœŸ** | {created} |
| **ä½œè€…** | YYCÂ³ Team |
| **æ›´æ–°æ—¥æœŸ** | {updated} |

---

"""

# ç›®å½•æ¨¡æ¿
TOC_TEMPLATE = """## ğŸ“‘ ç›®å½•

{toc_items}

---

"""

class DocumentImprover:
    """æ–‡æ¡£æ”¹è¿›å™¨"""
    
    def __init__(self, docs_root: str):
        self.docs_root = Path(docs_root)
        self.stats = {
            "total_docs": 0,
            "short_content": 0,
            "missing_sections": 0,
            "missing_toc": 0,
            "missing_info_table": 0,
            "improved": 0
        }
    
    def find_all_markdown_files(self) -> List[Path]:
        """æŸ¥æ‰¾æ‰€æœ‰Markdownæ–‡ä»¶"""
        md_files = []
        for root, dirs, files in os.walk(self.docs_root):
            # è·³è¿‡è„šæœ¬å·¥å…·æ–‡ä»¶å¤¹
            if "è„šæœ¬å·¥å…·" in root:
                continue
            for file in files:
                if file.endswith('.md'):
                    md_files.append(Path(root) / file)
        return md_files
    
    def analyze_document(self, file_path: Path) -> Dict:
        """åˆ†ææ–‡æ¡£"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
        except Exception as e:
            print(f"âŒ æ— æ³•è¯»å–æ–‡ä»¶ {file_path}: {e}")
            return None
        
        lines = content.split('\n')
        
        # ç»Ÿè®¡æœ‰æ•ˆå†…å®¹è¡Œæ•°ï¼ˆæ’é™¤ç©ºè¡Œå’Œæ³¨é‡Šè¡Œï¼‰
        content_lines = [line for line in lines if line.strip() and not line.strip().startswith('#')]
        effective_lines = len(content_lines)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ–‡æ¡£ä¿¡æ¯è¡¨æ ¼
        has_info_table = '## ğŸ“‹ æ–‡æ¡£ä¿¡æ¯' in content or '## æ–‡æ¡£ä¿¡æ¯' in content
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ç›®å½•
        has_toc = '## ğŸ“‘ ç›®å½•' in content or '## ç›®å½•' in content
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ ‡å‡†ç« èŠ‚
        has_standard_sections = any(section in content for section in ['## 1. æ¦‚è¿°', '## 1. è¯´æ˜'])
        
        # æå–æ–‡æ¡£å…ƒæ•°æ®
        metadata = self.extract_metadata(content, file_path)
        
        return {
            'file_path': file_path,
            'effective_lines': effective_lines,
            'has_info_table': has_info_table,
            'has_toc': has_toc,
            'has_standard_sections': has_standard_sections,
            'metadata': metadata,
            'content': content
        }
    
    def extract_metadata(self, content: str, file_path: Path) -> Dict:
        """æå–æ–‡æ¡£å…ƒæ•°æ®"""
        metadata = {
            'title': '',
            'doc_type': '',
            'phase': '',
            'version': 'v1.0.0',
            'created': '2025-01-30',
            'updated': '2025-01-30'
        }
        
        # ä»æ–‡ä»¶å¤´éƒ¨æå–å…ƒæ•°æ®
        lines = content.split('\n')[:20]
        for line in lines:
            if line.startswith('**@description**ï¼š'):
                metadata['title'] = line.split('ï¼š', 1)[1].strip()
            elif line.startswith('**@version**ï¼š'):
                metadata['version'] = line.split('ï¼š', 1)[1].strip()
            elif line.startswith('**@created**ï¼š'):
                metadata['created'] = line.split('ï¼š', 1)[1].strip()
            elif line.startswith('**@updated**ï¼š'):
                metadata['updated'] = line.split('ï¼š', 1)[1].strip()
        
        # ä»æ–‡ä»¶è·¯å¾„æ¨æ–­æ–‡æ¡£ç±»å‹å’Œé˜¶æ®µ
        path_parts = str(file_path).split('/')
        for part in path_parts:
            if 'æ¶æ„è®¾è®¡' in part:
                metadata['doc_type'] = 'æ¶æ„è®¾è®¡æ–‡æ¡£'
                metadata['phase'] = 'æ¶æ„è®¾è®¡'
            elif 'å¼€å‘å®æ–½' in part:
                metadata['doc_type'] = 'å¼€å‘å®æ–½æ–‡æ¡£'
                metadata['phase'] = 'å¼€å‘å®æ–½'
            elif 'æŠ€å·§ç±»' in part:
                metadata['doc_type'] = 'æŠ€å·§ç±»æ–‡æ¡£'
                metadata['phase'] = 'å¼€å‘å®æ–½'
            elif 'éƒ¨ç½²å‘å¸ƒ' in part:
                metadata['doc_type'] = 'éƒ¨ç½²å‘å¸ƒæ–‡æ¡£'
                metadata['phase'] = 'éƒ¨ç½²å‘å¸ƒ'
            elif 'è¿ç»´è¿è¥' in part:
                metadata['doc_type'] = 'è¿ç»´è¿è¥æ–‡æ¡£'
                metadata['phase'] = 'è¿ç»´è¿è¥'
            elif 'æµ‹è¯•éªŒè¯' in part:
                metadata['doc_type'] = 'æµ‹è¯•éªŒè¯æ–‡æ¡£'
                metadata['phase'] = 'æµ‹è¯•éªŒè¯'
            elif 'éœ€æ±‚è§„åˆ’' in part:
                metadata['doc_type'] = 'éœ€æ±‚è§„åˆ’æ–‡æ¡£'
                metadata['phase'] = 'éœ€æ±‚è§„åˆ’'
            elif 'ç”¨æˆ·æŒ‡å—' in part:
                metadata['doc_type'] = 'ç”¨æˆ·æŒ‡å—æ–‡æ¡£'
                metadata['phase'] = 'ç”¨æˆ·æŒ‡å—'
            elif 'å½’ç±»è¿­ä»£' in part:
                metadata['doc_type'] = 'å½’ç±»è¿­ä»£æ–‡æ¡£'
                metadata['phase'] = 'å½’ç±»è¿­ä»£'
        
        if not metadata['title']:
            metadata['title'] = file_path.stem
        
        return metadata
    
    def generate_toc(self, content: str) -> str:
        """ç”Ÿæˆç›®å½•"""
        lines = content.split('\n')
        toc_items = []
        
        for line in lines:
            if line.startswith('##'):
                # æå–æ ‡é¢˜çº§åˆ«å’Œæ–‡æœ¬
                match = re.match(r'^(#{2,4})\s+(.+)', line)
                if match:
                    level = len(match.group(1))
                    text = match.group(2)
                    # ç”Ÿæˆé”šç‚¹
                    anchor = text.lower().replace(' ', '-').replace('ï¼š', '').replace('ï¼š', '')
                    indent = '  ' * (level - 2)
                    toc_items.append(f"{indent}- [{text}](#{anchor})")
        
        return '\n'.join(toc_items)
    
    def improve_document(self, doc_info: Dict) -> bool:
        """æ”¹è¿›æ–‡æ¡£"""
        content = doc_info['content']
        metadata = doc_info['metadata']
        file_path = doc_info['file_path']
        
        improved = False
        new_content = content
        
        # 1. æ·»åŠ æ–‡æ¡£ä¿¡æ¯è¡¨æ ¼
        if not doc_info['has_info_table']:
            print(f"  ğŸ“ æ·»åŠ æ–‡æ¡£ä¿¡æ¯è¡¨æ ¼: {file_path.name}")
            
            # æ‰¾åˆ°æ’å…¥ä½ç½®ï¼ˆåœ¨æ–‡æ¡£å¤´éƒ¨ä¹‹åï¼‰
            header_end = new_content.find('---\n\n')
            if header_end != -1:
                insert_pos = header_end + 5
                info_table = DOC_INFO_TABLE.format(
                    title=metadata['title'],
                    doc_type=metadata['doc_type'],
                    phase=metadata['phase'],
                    version=metadata['version'],
                    created=metadata['created'],
                    updated=metadata['updated']
                )
                new_content = new_content[:insert_pos] + info_table + new_content[insert_pos:]
                improved = True
                self.stats['missing_info_table'] += 1
        
        # 2. æ·»åŠ ç›®å½•
        if not doc_info['has_toc']:
            print(f"  ğŸ“‘ æ·»åŠ ç›®å½•: {file_path.name}")
            
            # æ‰¾åˆ°æ–‡æ¡£ä¿¡æ¯è¡¨æ ¼ä¹‹åçš„ä½ç½®
            info_table_end = new_content.find('---\n\n', new_content.find('## ğŸ“‹ æ–‡æ¡£ä¿¡æ¯'))
            if info_table_end != -1:
                insert_pos = info_table_end + 5
                
                # ç”Ÿæˆç›®å½•
                toc_items = self.generate_toc(new_content)
                if toc_items:
                    toc = TOC_TEMPLATE.format(toc_items=toc_items)
                    new_content = new_content[:insert_pos] + toc + new_content[insert_pos:]
                    improved = True
                    self.stats['missing_toc'] += 1
        
        # 3. æ·»åŠ æ ‡å‡†ç« èŠ‚ï¼ˆå¦‚æœç¼ºå°‘ï¼‰
        if not doc_info['has_standard_sections']:
            print(f"  ğŸ“š æ·»åŠ æ ‡å‡†ç« èŠ‚: {file_path.name}")
            
            # ç¡®å®šä½¿ç”¨å“ªä¸ªç« èŠ‚æ¨¡æ¿
            phase = metadata['phase']
            if phase in STANDARD_SECTIONS:
                sections = STANDARD_SECTIONS[phase]
            else:
                sections = STANDARD_SECTIONS['é»˜è®¤']
            
            # æ‰¾åˆ°ç›®å½•ä¹‹åçš„ä½ç½®
            toc_end = new_content.find('---\n\n', new_content.find('## ğŸ“‘ ç›®å½•'))
            if toc_end != -1:
                insert_pos = toc_end + 5
                sections_text = '\n\n'.join(sections) + '\n\n'
                new_content = new_content[:insert_pos] + sections_text + new_content[insert_pos:]
                improved = True
                self.stats['missing_sections'] += 1
        
        # 4. è¡¥å……å†…å®¹è¿‡å°‘çš„æ–‡æ¡£
        if doc_info['effective_lines'] < 50:
            print(f"  âš ï¸  å†…å®¹è¿‡å°‘ ({doc_info['effective_lines']}è¡Œ): {file_path.name}")
            self.stats['short_content'] += 1
            # è¿™é‡Œå¯ä»¥æ·»åŠ è¡¥å……å†…å®¹çš„é€»è¾‘
        
        # ä¿å­˜æ”¹è¿›åçš„æ–‡æ¡£
        if improved:
            try:
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(new_content)
                self.stats['improved'] += 1
                print(f"  âœ… å·²æ”¹è¿›: {file_path.name}")
                return True
            except Exception as e:
                print(f"  âŒ ä¿å­˜å¤±è´¥: {e}")
                return False
        
        return False
    
    def run(self, dry_run: bool = False):
        """è¿è¡Œæ”¹è¿›æµç¨‹"""
        print("ğŸš€ å¼€å§‹æ‰§è¡Œç¬¬ä¸€é˜¶æ®µï¼ˆP0ï¼‰æ–‡æ¡£æ”¹è¿›...")
        print(f"ğŸ“ æ–‡æ¡£æ ¹ç›®å½•: {self.docs_root}")
        print()
        
        # æŸ¥æ‰¾æ‰€æœ‰Markdownæ–‡ä»¶
        md_files = self.find_all_markdown_files()
        self.stats['total_docs'] = len(md_files)
        
        print(f"ğŸ“Š æ‰¾åˆ° {len(md_files)} ä¸ªMarkdownæ–‡ä»¶")
        print()
        
        # åˆ†æå’Œæ”¹è¿›æ¯ä¸ªæ–‡æ¡£
        for i, file_path in enumerate(md_files, 1):
            print(f"[{i}/{len(md_files)}] å¤„ç†: {file_path.name}")
            
            doc_info = self.analyze_document(file_path)
            if doc_info:
                if not dry_run:
                    self.improve_document(doc_info)
                else:
                    # ä»…åˆ†æï¼Œä¸ä¿®æ”¹
                    if doc_info['effective_lines'] < 50:
                        print(f"  âš ï¸  å†…å®¹è¿‡å°‘ ({doc_info['effective_lines']}è¡Œ)")
                        self.stats['short_content'] += 1
                    if not doc_info['has_info_table']:
                        print(f"  ğŸ“ ç¼ºå°‘æ–‡æ¡£ä¿¡æ¯è¡¨æ ¼")
                        self.stats['missing_info_table'] += 1
                    if not doc_info['has_toc']:
                        print(f"  ğŸ“‘ ç¼ºå°‘ç›®å½•")
                        self.stats['missing_toc'] += 1
                    if not doc_info['has_standard_sections']:
                        print(f"  ğŸ“š ç¼ºå°‘æ ‡å‡†ç« èŠ‚")
                        self.stats['missing_sections'] += 1
            
            print()
        
        # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
        self.print_stats()
    
    def print_stats(self):
        """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
        print("=" * 60)
        print("ğŸ“Š æ”¹è¿›ç»Ÿè®¡")
        print("=" * 60)
        print(f"æ€»æ–‡æ¡£æ•°: {self.stats['total_docs']}")
        print(f"å†…å®¹è¿‡å°‘æ–‡æ¡£: {self.stats['short_content']}")
        print(f"ç¼ºå°‘æ ‡å‡†ç« èŠ‚: {self.stats['missing_sections']}")
        print(f"ç¼ºå°‘ç›®å½•: {self.stats['missing_toc']}")
        print(f"ç¼ºå°‘æ–‡æ¡£ä¿¡æ¯è¡¨æ ¼: {self.stats['missing_info_table']}")
        print(f"å·²æ”¹è¿›æ–‡æ¡£: {self.stats['improved']}")
        print("=" * 60)


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='YYCÂ³æ–‡æ¡£é—­ç¯ç³»ç»Ÿç¬¬ä¸€é˜¶æ®µï¼ˆP0ï¼‰æ”¹è¿›è„šæœ¬')
    parser.add_argument('--dry-run', action='store_true', help='ä»…åˆ†æï¼Œä¸ä¿®æ”¹æ–‡ä»¶')
    parser.add_argument('--docs-root', default=DOCS_ROOT, help='æ–‡æ¡£æ ¹ç›®å½•')
    
    args = parser.parse_args()
    
    improver = DocumentImprover(args.docs_root)
    improver.run(dry_run=args.dry_run)


if __name__ == '__main__':
    main()
